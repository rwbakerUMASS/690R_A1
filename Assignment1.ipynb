{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688a0279",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission.*\n",
    "\n",
    "*Note that this assignment was designed to run in the **Jupyter Notebook** environment.*\n",
    "\n",
    "The assignment has three tasks:\n",
    "\n",
    "- Task 1: Understanding the limitations of double-integrating acceleration time-series to obtain position time-series and exploring the efficacy of low-pass filter (LPF) in reducing noice.\n",
    "- Task 2: Experimenting with sensor fusion algorithms to obtain acceleration in the global coordinate system while the sensor is in motion and assessing the associated challenges to gain insights into the complexity of the task.\n",
    "- Task 3: Experimenting with sensor fusion algorithms to obtain acceleration in the global coordinate system while the sensor is moving randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a510c66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:02.807983Z",
     "start_time": "2024-02-15T15:29:00.236094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from types import SimpleNamespace\n",
    "from scipy.signal import find_peaks, resample, butter, filtfilt\n",
    "from scipy.integrate import cumtrapz\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from cs690r.data_utils import load_sensor_from_csv, load_mocap_from_tsv, trim_data \n",
    "from cs690r.plot_utils import plot_time_series, animate_trajectory, compare_trajectory\n",
    "\n",
    "# The commands will allow the notebook to reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc692b",
   "metadata": {},
   "source": [
    "[`Attitude and Heading Reference Systems (AHRS)`](https://ahrs.readthedocs.io/en/latest/index.html) is a Python library for sensor fusion, specifically for estimating orientation from inertial measurement unit (IMU) data, which typically includes acceleration and angular velocity measurements.\n",
    "\n",
    "To download and install the package, you can use the following command in their terminal or command prompt:\n",
    "\n",
    "```bash\n",
    "pip install ahrs\n",
    "```\n",
    "\n",
    "Refer to this [page](https://ahrs.readthedocs.io/en/latest/installation.html) for more detailed information about ahrs installation. \n",
    "\n",
    "Once you install the package, you can import and use the ahrs.filters module for sensor fusion algorithms in you Python scripts or Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81539305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:03.004344Z",
     "start_time": "2024-02-15T15:29:02.813314Z"
    }
   },
   "outputs": [],
   "source": [
    "from ahrs.filters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc4531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:03.121956Z",
     "start_time": "2024-02-15T15:29:03.011501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define gravity constant\n",
    "GRAVITY_CONSTANT = 9.80665"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f15d8",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "You can find the data for Task 1 in the \"data\" folder. In this task, a sensor equipped with accelerometer, gyroscope, and magnetometer was placed on a stationary horizontal surface. To facilitate this process, a function for loading sensor data from text files has been implemented for students. This function is located in the \"cs690r.data_utils\" module.\n",
    "\n",
    "You can access the attributes of sensor data using the following code\n",
    "```python\n",
    "sample_rate = sensor_data.sample_rate # sampling rate of the sensor, 100Hz\n",
    "acc = sensor_data.acc # acceleration, unit: m/s^2\n",
    "gyr = sensor_data.gyr # angular velocity, unit: rad/s\n",
    "mag = sensor_data.mag # magnetometer data, unit: a.u. (arbitrary units; normalized to earth field strength)\n",
    "\n",
    "free_acc = sensor_data.free_acc # the sensor's manufacturer (Movella XSens) has its proprietary algorithm to estimate the gravity-free acceleration in the global coordinates\n",
    "```\n",
    "\n",
    "Please note that the data in the file is raw and unfiltered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abbf78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:03.749479Z",
     "start_time": "2024-02-15T15:29:03.136171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load stationary data\n",
    "task1_sensor_file = os.path.join('data', 'task1_sensor_data.csv')\n",
    "task1_sensor_data = load_sensor_from_csv(task1_sensor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9e2f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:03.818261Z",
     "start_time": "2024-02-15T15:29:03.752804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove gravity from the z-axis, given that the sensor was placed stationary\n",
    "task1_sensor_data.acc[:, 2] -= GRAVITY_CONSTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaad97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T14:25:11.521446Z",
     "start_time": "2024-01-19T14:25:10.883645Z"
    }
   },
   "source": [
    "**Task 1.1**: \n",
    "\n",
    "1) Implement the `filtering_and_integrate` function provided below. In this function, use a 6th order Butterworth filter with a cut-off frequency of 8 Hz to low-pass filter the raw acceleration and angular velocity, respectively. Integrate the filtered acceleration to derive the velocity time-series, followed by band-pass filtering (2nd order Butterworth) with cut-off frequency between 0.1 Hz and 8 Hz to address integration drift and high-frequency noise. Repeat the integration and band-pass filtering process to the derived velocity time-series to get position time-series.\n",
    "\n",
    "2) Apply `filtering_and_integrate` to `task1_sensor_data`. Specifically, double-integrate the acceleration time-series to obtain position time-series both **with and without filtering**.\n",
    "\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "1) For integration, consider [`scipy.integrate.cumtrapz`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.integrate.cumtrapz.html) or [`scipy.integrate.cumulative_trapezoid`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.cumulative_trapezoid.html) for integration depending on the version of `scipy` you are using. You are also free to use other integration implementations you are familiar with.\n",
    "\n",
    "2) For filtering, checkout `Filtering Example.ipynb` in this folder to learn how to design different types of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d0c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:03.894458Z",
     "start_time": "2024-02-15T15:29:03.821780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1.1.1: Implement the `filtering_and_integrate` function provided below\n",
    "def filtering_and_integrate(data, use_filter=True):\n",
    "    '''\n",
    "    Input Parameters\n",
    "    ----------\n",
    "    data : sensor data object\n",
    "        To access the acceleration, use:\n",
    "        acc = data.acc\n",
    "\n",
    "    use_filter : boolean\n",
    "        If use_filter is set to True,\n",
    "        low-pass and band-pass filters will be applied to the data\n",
    "        \n",
    "    Output Parameters\n",
    "    -----------\n",
    "    data : sensor data object with filtered data\n",
    "        data.acc: filtered acceleration\n",
    "        data.vel: integrated, filtered velocity\n",
    "        data.pos: integrated, filtered position\n",
    "        data.gyr: filtered angular velocity\n",
    "    '''\n",
    "    data = copy.deepcopy(data)\n",
    "\n",
    "    # Get acceleration\n",
    "    acc = data.acc.copy()\n",
    "    \n",
    "    # Get angular velocity\n",
    "    gyr = data.gyr.copy()\n",
    "    \n",
    "    # Get the sampling rate of the sensor\n",
    "    sample_rate = data.sample_rate\n",
    "\n",
    "    ####################################################################\n",
    "    # TODO: Define low-pass filter and band-pass filter\n",
    "    # apply the filters on the sensor acceleration and angular velocity\n",
    "    # if use_filter is True\n",
    "    # integrate the acceleration to get velocity and position\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################################################\n",
    "    \n",
    "    # Save acceleration, velocity, position, and angular velocity\n",
    "    data.acc = acc\n",
    "    data.vel = vel\n",
    "    data.pos = pos\n",
    "    data.gyr = gyr\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80d3f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:03.961279Z",
     "start_time": "2024-02-15T15:29:03.897810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1.1.2: Apply `filtering_and_integrate` on task1_sensor_data \n",
    "# with and without filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45909826",
   "metadata": {},
   "source": [
    "**Task 1.2**\n",
    "\n",
    "1) Apply `plot_time_series` (located in plot_utils.py) to generate 1D time series plots for acceleration, velocity, and position in each scenario (with and without filtering).\n",
    "\n",
    "2) Animate the position time-series derived from with/without a low-pass filter using the provided `animate_trajectory` (located in plot_utils.py).\n",
    "\n",
    "Even though the sensor was placed on a horizontal surface, the raw unfiltered acceleration does not seem to be perfectly zero due to imperfect calibration and inherent sensor noise. Integrating the raw unfiltered acceleration to obtain velocity and position may cause significant drift over time. However, utilizing a low-pass filter and a band-pass filter can effectively mitigate this drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc9b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:04.032614Z",
     "start_time": "2024-02-15T15:29:03.967580Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exercise 1.2.1: Plot 1D time series for acceleration, velocity, and position\n",
    "# in each scenario (i.e. with/without filtering) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e87dcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:04.103786Z",
     "start_time": "2024-02-15T15:29:04.038484Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1.2.2: Animate the position time-series\n",
    "# obtained with filtering and without filtering\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f61fd2",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "In this task, an 9-axis inertial measurement unit (referred to as *sensor*) was moved along a rectangular trajectory within 3D space (i.e., the trajectory discussed in class). The sensor captured the three-axis accelerometer, three-axis gyroscope, and three-axis magnetometer time-series. Moreover, a reflective marker was also placed on the sensor to capture the three-axis position time-series using a motion caption system (referred to as *mocap*). \n",
    "\n",
    "Note that we have used *hand clapping* to synchronize the mocap and sensor data.\n",
    "\n",
    "You can find the data for Task 2 in the \"data\" folder. The sensor data were saved in `task_2_sensor_data.csv`, whereas the mocap data were saved in `task2_mocap_data.tsv`. You may use `load_sensor_from_csv` and `load_mocap_from_tsv` functions provided in `data_utils.py` to load the data.\n",
    "\n",
    "You can access the attributes of mocap data by using the following code\n",
    "```python\n",
    "sample_rate = mocap_data.sample_rate # sampling rate of the mocap system, 150Hz\n",
    "raw_pos = mocap_data.raw_pos # position, unit: m\n",
    "```\n",
    "\n",
    "Please note that the data in the files are raw and unfiltered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a77254",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:04.312268Z",
     "start_time": "2024-02-15T15:29:04.106653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load sensor data\n",
    "task2_sensor_file = os.path.join('data', 'task2_sensor_data.csv')\n",
    "task2_sensor_data = load_sensor_from_csv(task2_sensor_file)\n",
    "\n",
    "# Load mocap data\n",
    "task2_mocap_file = os.path.join('data', 'task2_mocap_data.tsv')\n",
    "task2_mocap_data = load_mocap_from_tsv(task2_mocap_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3f064",
   "metadata": {},
   "source": [
    "Run the following code to visualize the raw acceleration and angular velocity captured by the sensor. Note that the data collector clapped multiple times before and after the data collection, resulting in large peaks in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29614954",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:30:04.604377Z",
     "start_time": "2024-02-15T15:30:04.254027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the sensor's raw acceleration and angular velocity\n",
    "n_rows = 2\n",
    "n_cols = 1\n",
    "row_sz = 3\n",
    "col_sz = 7\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(n_cols*col_sz, n_rows*row_sz))\n",
    "ax = fig.add_subplot(211)\n",
    "ax.plot(task2_sensor_data.acc)\n",
    "ax.set_xlabel('Frame')\n",
    "ax.set_ylabel('Acc ($m/s^2$)')\n",
    "ax.set_title('Sensor raw acceleration')\n",
    "ax.legend(['X-axis', 'Y-axis', 'Z-axis'])\n",
    "\n",
    "ax = fig.add_subplot(212)\n",
    "ax.plot(task2_sensor_data.gyr)\n",
    "ax.set_xlabel('Frame')\n",
    "ax.set_ylabel('Angular vel ($rad/s$)')\n",
    "ax.set_title('Sensor raw angular velocity')\n",
    "ax.legend(['X-axis', 'Y-axis', 'Z-axis'])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d92b22",
   "metadata": {},
   "source": [
    "**Task 2.1**\n",
    "\n",
    "1) Implement the `filtering_and_gradient` function provided below. In this function, use a 6th order Butterworth filter with a cut-off frequency of 8 Hz to low-pass filter the raw position captured by the mocap system. Compute the gradient of the filtered position to derive the velocity time-series, followed by the same low-pass filter. Repeat the process of taking gradient and low-pass filtering to the velocity times-series to acquire acceleration time-series.\n",
    "\n",
    "2) Apply `filtering_and_gradient` to `task2_mocap_data`. \n",
    "\n",
    "3) Apply `filtering_and_integrate` from Task 1 to `task2_sensor_data`.\n",
    "\n",
    "**Hint**\n",
    "\n",
    "1) For gradient, you can use [`numpy.gradient`](https://numpy.org/doc/stable/reference/generated/numpy.gradient.html). You are also free to use other integration implementations you are familiar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a279bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:05.387885Z",
     "start_time": "2024-02-15T15:29:05.270426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.1.1 Implement the `filtering_and_gradient` function provided below\n",
    "def filtering_and_gradient(data):\n",
    "    '''\n",
    "    Input Parameters\n",
    "    ----------\n",
    "    data : mocap data object\n",
    "        To access the position, use:\n",
    "        pos = data.pos\n",
    "        \n",
    "    Output Parameters\n",
    "    -----------\n",
    "    data : mocap data object with filtered data\n",
    "        data.pos: filtered position\n",
    "        data.vel: filtered velocity\n",
    "        data.acc: filtered position\n",
    "    '''\n",
    "    data = copy.deepcopy(data)\n",
    "    \n",
    "    # Get raw position\n",
    "    pos = data.pos.copy()\n",
    "    \n",
    "    # Get the sampling rate of the sensor\n",
    "    sample_rate = data.sample_rate\n",
    "    \n",
    "    ####################################################################\n",
    "    # TODO: Define low-pass filter\n",
    "    # apply the filters on the data\n",
    "    # take the gradient of the position to get velocity and acceleration\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################################################\n",
    "    \n",
    "    # Save filtered acceleration, velocity, and position\n",
    "    data.pos = pos\n",
    "    data.vel = vel\n",
    "    data.acc = acc\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94db0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:05.487749Z",
     "start_time": "2024-02-15T15:29:05.390820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.1.2: Apply `filtering_and_gradient` on task2_mocap_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21509929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:05.581687Z",
     "start_time": "2024-02-15T15:29:05.490593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.1.3: Apply `filtering_and_integrate` on task2_sensor_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4470ca9",
   "metadata": {},
   "source": [
    "**Task 2.2**\n",
    "\n",
    "\n",
    "In this task, you will delve into synchronizing data captured from disparate sensing systems. Variations in sampling rates or other factors often introduce discrepancies in the collected data. To facilitate synchronization, the data collector performed multiple claps while holding the sensor (which was attached with a mocap marker) before and after data collection. This resulted in large peaks in acceleration, as shown in our previous plots. Leveraging these claps, we can align different data by trimming segments between the claps and resampling to a uniform sampling rate.\n",
    "\n",
    "1) Run the provided code to trim both sensor and mocap data.\n",
    "\n",
    "2) Implement the `resampling_mocap` function. In the function, use [`scipy.signal.resample`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html) to resample the mocap acceleration, velocity, and position, in order to match the sampling rate of the sensor data. We opt to reduce the sampling rate of the mocap data to align with that of the sensor data, aiming to maintain data integrity (compared to upsampling the sensor data to match the mocap data, which entails data interpolation and may compromise integrity).\n",
    "\n",
    "3) Apply `resampling_mocap` to `task2_mocap_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61a17d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.428539Z",
     "start_time": "2024-02-15T15:29:05.588556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.2.1: Run the provided code to trim both sensor and mocap data.\n",
    "# The clapping indices were identified by manual inspection of the two data. \n",
    "sensor_start, sensor_end = 1183, 4431 # task 2\n",
    "task2_sensor_data = trim_data(task2_sensor_data, sensor_start, sensor_end, 'sensor')\n",
    "\n",
    "mocap_start, mocap_end = 1981, 6812 # task 2\n",
    "task2_mocap_data = trim_data(task2_mocap_data, mocap_start, mocap_end, 'mocap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb18ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.437765Z",
     "start_time": "2024-02-15T15:29:00.293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.2.2: Implement the `resampling_mocap` function provided below\n",
    "def resampling_mocap(data, num):\n",
    "    '''\n",
    "    Input Parameters\n",
    "    ----------\n",
    "    data : mocap data object\n",
    "    \n",
    "    num : int, the number of samples in the resampled signal\n",
    "    \n",
    "    Output Parameters\n",
    "    ----------\n",
    "    data : mocap data object with resampled pos, vel and acc\n",
    "    '''\n",
    "    data = copy.deepcopy(data)\n",
    "    \n",
    "    ####################################################################\n",
    "    # TODO: resample acceleration, velocity, and position\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################################################\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f7d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.440733Z",
     "start_time": "2024-02-15T15:29:00.296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.2.3: Apply `resampling_mocap` to `task2_mocap_data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4290e",
   "metadata": {},
   "source": [
    "**Task 2.3**\n",
    "\n",
    "This task will demonstrate the process of fusing acceleration and angular velocity data collected in the sensor's coordinate system to estimate the sensor's orientation in the global coordinate system. Once the orientation is determined, this information can be utilized to align or rotate the sensor to the global coordinate system.\n",
    "\n",
    "1) Implement the `fuse_and_rotate` function. Firstly, select a method from `ahrs` to estimate the sensor's orientation. Secondly, utilize the estimated orientation to transform the acceleration and angular velocity from the sensor's coordinate system to the global coordinates. Thirdly, remove gravity from the vertical axis of the global coordinate acceleration. Finally, apply `filtering_and_integrate` from Task 1 to the transformed gravity-free, global-coordinate acceleration to derive velocity and position time-series in the global coordinates.\n",
    "\n",
    "2) Apply `fuse_and_rotate` to `task2_sensor_data` to obtain acceleration, velocity, and position time-series in the global coordinates.\n",
    "\n",
    "3) Utilize `compare_trajectory` to visualize the acceleration, velocity, and position from both the sensor and mocap systems in the global coordinates.\n",
    "\n",
    "**Hint**\n",
    "\n",
    "1) You can choose from the following methods provided by AHRS to estimate sensor orientation. The methods shown in the table below assume that the Z-axis of the global coordinate system aligns with gravity. Therefore, you can easily eliminate gravity from the transformed acceleration.\n",
    "\n",
    "| Fusion Method                                                           | Orientatio<br>Representation | What to set inverse in<br>`R.from_quat().apply()` |\n",
    "|-------------------------------------------------------------------------|----------------------------|------------------------------------------------|\n",
    "| [AQUA](https://ahrs.readthedocs.io/en/latest/filters/aqua.html)         | global -> local            | True                                           |\n",
    "| [Madgwich](https://ahrs.readthedocs.io/en/latest/filters/madgwick.html) | local -> global            | False                                          |\n",
    "| [Mahony](https://ahrs.readthedocs.io/en/latest/filters/mahony.html)     | local -> global            | False                                          |\n",
    "\n",
    "Here's an example of sensor orientation estimation using `AQUA` from `ahrs`. Suppose you have acceleration data `acc` in m/s^2 and angular velocity data `gyr` in rad/s, sampled at a frequency of `sample_freq` Hz. To estimate the orientation, you can follow these steps:\n",
    "\n",
    "```python\n",
    "ahrs_filter = AQUA(acc=acc, gyr=gyr, frequency=sample_freq) # define sensor fusion method\n",
    "orientation = ahrs_filter.Q # access the orientation\n",
    "```\n",
    "\n",
    "The `orientation` calculated by `AQUA` represents the global to local transformation, whereas for Madgwick and Mahony, it represents the local to global transformation. You need to be careful with this difference when using them for future coordinate transformation.\n",
    "\n",
    "2) For coordinate transformation, you can use [`scipy.spatial.transform.Rotation`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.html). Assume the local acceleration captured in the sensor local frame is `local_acc` and the `orientation` transforms the data from the sensor local frame to the global frame. To perform transformation,\n",
    "\n",
    "```python\n",
    "orientation = orientation[:, [1, 2, 3, 0]] # the orientation calculated from ahrs has different form than what is required by R.from_quat\n",
    "\n",
    "global_acc = R.from_quat(orientation).apply(local_acc, inverse=True) # inverse needs to be set to `True` because the orientation calcuated from AQUA represents the transformation from global coordinate system to the sensor coordinate system. For Madgwich and Mahony methods, `inverse` needs to be set to `False`.\n",
    "\n",
    "global_acc[:, 2] -= GRAVITY_CONSTANT # remove gravity from Z-axis\n",
    "```\n",
    "\n",
    "In the code above, if `inverse` is specificed `True` in `R.from_quat().apply()`, the inverse of the rotation(s) is applied to the input vectors. You can refer to the table above for guidance on how to set up this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a7295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.443504Z",
     "start_time": "2024-02-15T15:29:00.299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.3.1 Implement the `fuse_and_rotate` function\n",
    "def fuse_and_rotate(local_data):\n",
    "    '''\n",
    "    Input Parameters\n",
    "    ----------\n",
    "    local_data : sensor data object in sensor's coordinates\n",
    "    \n",
    "    Output Parameters\n",
    "    ----------\n",
    "    global_data : transformed data object in global coordinates\n",
    "        global_data.sample_rate: the synchornized sampling rate\n",
    "        global_data.acc: global 3D accelerometer\n",
    "        global_data.gyr: global 3D gyroscope\n",
    "    '''\n",
    "    local_data = copy.deepcopy(local_data)\n",
    "    \n",
    "    local_acc = local_data.acc\n",
    "    local_gyr = local_data.gyr\n",
    "    sample_rate = local_data.sample_rate\n",
    "    \n",
    "    ####################################################################\n",
    "    # TODO: Calculate sensor orientation, then use orientation to \n",
    "    # transform acceleration and angular velocity from sensor local \n",
    "    # frame to global frame\n",
    "    # Remove gravity from global acceleration\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################################################\n",
    "    \n",
    "    # Save the transformed data\n",
    "    global_data = SimpleNamespace()\n",
    "    global_data.sample_rate = local_data.sample_rate\n",
    "    global_data.acc = global_acc\n",
    "    global_data.gyr = global_gyr\n",
    "    \n",
    "    ####################################################################\n",
    "    # TODO: Apply filtering_and_integrate to global data\n",
    "    \n",
    "    ####################################################################\n",
    "    \n",
    "    return global_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20035250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.446657Z",
     "start_time": "2024-02-15T15:29:00.301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.3.2: Apply `fuse_and_rotate` on `task2_sensor_data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b49bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.464982Z",
     "start_time": "2024-02-15T15:29:00.304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.3.3: Compare acceleration, velocity, and position \n",
    "# from sensor fusion algorithm and mocap system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1bd97",
   "metadata": {},
   "source": [
    "**Task 2.4**\n",
    "\n",
    "In this exercise, you will evaluate the performance of the `ahrs` algorithm both quantitatively and qualitatively.\n",
    "\n",
    "1) Calculate the root mean square error (RMSE) and the normalized root mean square error (NRMSE) for acceleration, velocity, and position time-series obtained from your sensor fusion algorithm with the mocap data, respectively. NRMSE is obtained by normalizing the RMSE to the range of mocap data, so that the error can be represented in percentage (%). \n",
    "\n",
    "**When you calculate RMSE and NRMSE for the position time-series, make sure that both position time-series start at 0 (for fair comparison).**\n",
    "\n",
    "This analysis will provide insights into the accuracy and reliability of your sensor fusion algorithm compared to the ground truth mocap data.\n",
    "\n",
    "2) Create animations using `animate_trajectory` for the position time-series derived from the sensor fusion algorithm and captured by the mocap system, respectively. By visually comparing these animations, you can qualitatively assess how well the sensor fusion algorithm aligns with the mocap system in representing the sensor's movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf88843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.479559Z",
     "start_time": "2024-02-15T15:29:00.307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.4.1: Calculate RMSE and NRMSE for acceleration, velocity, \n",
    "# and position time-series, respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a3747c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.484158Z",
     "start_time": "2024-02-15T15:29:00.310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.4.2: Animate the position time-series derived from the motion capture system (i.e., groundtruth)\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a2c7ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.491125Z",
     "start_time": "2024-02-15T15:29:00.313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.4.3: Animate the position time-series derived from the sensor fusion algorithm\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c9f41",
   "metadata": {},
   "source": [
    "**Task 2.5**\n",
    "\n",
    "In this exercise, you will leverage the gravity-free acceleration data provided by the manufacturer Xsens, known for its accuracy in fusing multi-modal data to estimate sensor orientation and obtain acceleration in global coordinates. This will enable you to evaluate the manufacturer's algorithm performance and compare it with mocap data. Note that the sensor fusion algorithm by Xsens uses all nine-axis inertial data (accelerometer + gyroscope + magnetometer) compared to the AQUA algorithm that uses only six-axis data (accelerometer + gyroscope).\n",
    "\n",
    "1) Apply the `filtering_and_integrate` function to the manufacturer gravity-free acceleration data to derive velocity and position time-series.\n",
    "\n",
    "2) Utilize `compare_trajectory` to visualize the acceleration, velocity, and position from both the manufacturer's gravity-free data and mocap systems in the global coordinates. \n",
    "\n",
    "3) Calculate the RMSE and NRMSE between the acceleration, velocity, and position time-series derived from the manufacturer gravity-free acceleration and the mocap system, respectively.\n",
    "\n",
    "4) Generate animations for the position time-series derived from the gravity-free acceleration provided by the manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65f82a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.501147Z",
     "start_time": "2024-02-15T15:29:00.317Z"
    }
   },
   "outputs": [],
   "source": [
    "task2_gravity_free_data = SimpleNamespace()\n",
    "task2_gravity_free_data.sample_rate = task2_sensor_data.sample_rate\n",
    "task2_gravity_free_data.acc = task2_sensor_data.free_acc\n",
    "task2_gravity_free_data.gyr = task2_sensor_data.gyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e33538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.507517Z",
     "start_time": "2024-02-15T15:29:00.319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.5.1: Apply the `filtering_and_integrate` function \n",
    "# to the manufacturer gravity-free acceleration data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c77516",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.521708Z",
     "start_time": "2024-02-15T15:29:00.322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.5.2: Compare acceleration, velocity, and position \n",
    "# from manufecturer and mocap system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f310f57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.525830Z",
     "start_time": "2024-02-15T15:29:00.325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.5.3: Calculate RMSE and NRMSE for acceleration, velocity, \n",
    "# and position time-series, respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3522cf25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.540111Z",
     "start_time": "2024-02-15T15:29:00.328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.5.4: Animate the position time-series derived from manufecturer data\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849c270",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "You can find the data for Task 3 in the \"data\" folder. In this task, a nine-axis IMU and a mocap marker was placed on a human subject's wrist, who performed some arbitrary, patternless, and random upper-limb movements (e.g., swinging the arm in the air randomly). The sensor data were saved in `task_3_sensor_data.csv`, and the mocap data were saved in `task3_mocap_data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b45c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.544881Z",
     "start_time": "2024-02-15T15:29:00.330Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load sensor data\n",
    "task3_sensor_file = os.path.join('data', 'task3_sensor_data.csv')\n",
    "task3_sensor_data = load_sensor_from_csv(task3_sensor_file)\n",
    "\n",
    "# Load mocap data\n",
    "task3_mocap_file = os.path.join('data', 'task3_mocap_data.tsv')\n",
    "task3_mocap_data = load_mocap_from_tsv(task3_mocap_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f593ada3",
   "metadata": {},
   "source": [
    "The objective of Task 3 is to apply the same procedures (Task 2.1 - 2.5) to this dataset, aiming to assess the algorithm's capability to handle entirely unpredictable movements that simulate daily scenarios.\n",
    "\n",
    "1) Apply `filtering_and_gradient` to `task3_mocap_data`. \n",
    "\n",
    "2) Apply `filtering_and_integrate` to `task3_sensor_data` with filtering. \n",
    "\n",
    "3) Synchronization and resampling. Trim the sensor data and mocap between the provided clapping indices. Then, apply `resampling_mocap` to resample to the mocap data to match the sampling rate of sensor data.\n",
    "\n",
    "4) Apply `fuse_and_rotate` on the sensor data.\n",
    "\n",
    "5) Utilize `compare_trajectory` to visualize the acceleration, velocity, and position from both the sensor and mocap systems in the global coordinates.\n",
    "\n",
    "6) Calculate the RMSE and NRMSE between the acceleration, velocity, and position time-series derived from the `ahrs` and the mocap system, respectively.\n",
    "\n",
    "7) Create animations using `animate_trajectory` for the position time-series derived from the sensor fusion algorithm and captured by the mocap system, respectively.\n",
    "\n",
    "8) Repeat Task 2.5 with data provided by the manufecturer in `task3_sensor_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92adc464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.557290Z",
     "start_time": "2024-02-15T15:29:00.333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.1: Apply `filtering_and_gradient` to `task3_mocap_data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2b170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.561040Z",
     "start_time": "2024-02-15T15:29:00.336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.2: Apply `filtering_and_integrate` to `task3_sensor_data` with filtering. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ce6c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.571875Z",
     "start_time": "2024-02-15T15:29:00.338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.3: Synchronization and resampling\n",
    "sensor_start, sensor_end = 918, 5198 # task 3\n",
    "task3_sensor_data = trim_data(task3_sensor_data, sensor_start, sensor_end, 'sensor')\n",
    "\n",
    "mocap_start, mocap_end = 1300, 7719 # task 3\n",
    "task3_mocap_data = trim_data(task3_mocap_data, mocap_start, mocap_end, 'mocap')\n",
    "\n",
    "# TODO: Apply `resampling_mocap` to resample to the mocap data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e4a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.574946Z",
     "start_time": "2024-02-15T15:29:00.341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.4: Apply `fuse_and_rotate` on the sensor data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b3f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.587352Z",
     "start_time": "2024-02-15T15:29:00.344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.5: Compare acceleration, velocity, and position from sensor fusion algorithm\n",
    "# and mocap system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfd525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.590778Z",
     "start_time": "2024-02-15T15:29:00.346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.6: Calculate RMSE and NRMSE obtained from your sensor fusion algorithm with the mocap data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d33af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.599397Z",
     "start_time": "2024-02-15T15:29:00.349Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.7: Animate the position time-series captured by the mocap system\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715c7b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.607610Z",
     "start_time": "2024-02-15T15:29:00.352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.7: Animate the position time-series derived from the sensor fusion algorithm\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b18b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.610684Z",
     "start_time": "2024-02-15T15:29:00.354Z"
    }
   },
   "outputs": [],
   "source": [
    "task3_gravity_free_data = SimpleNamespace()\n",
    "task3_gravity_free_data.sample_rate = task3_sensor_data.sample_rate\n",
    "task3_gravity_free_data.acc = task3_sensor_data.free_acc\n",
    "task3_gravity_free_data.gyr = task3_sensor_data.gyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b943e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.614237Z",
     "start_time": "2024-02-15T15:29:00.357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.8: Repeat Task 2.5 with data provided by the manufecturer in `task3_sensor_data`.\n",
    "# TODO: apply filtering_and_integrate on the manufecturer data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990415e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.620861Z",
     "start_time": "2024-02-15T15:29:00.360Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Compare acceleration, velocity, and position \n",
    "# from manufecturer and mocap system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6620451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.630634Z",
     "start_time": "2024-02-15T15:29:00.363Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate RMSE and NRMSE for acceleration, velocity, \n",
    "# and position time-series, respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af60b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T15:29:06.633880Z",
     "start_time": "2024-02-15T15:29:00.366Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Animate the position time-series derived from manufecturer data\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b2321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
